"""
Random Prediction Output Constructor

Used to test the robustness of anomaly detection metrics against random prediction scores by generating various types of random/weak baseline prediction outputs.

Based on datasets and labels generated by synthetic_anomaly_generator.py as the standard.
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from typing import Dict, List, Tuple, Optional, Union, Callable
from dataclasses import dataclass
from enum import Enum
import json
import copy
from scipy import stats
from sklearn.metrics import roc_auc_score, precision_recall_curve, f1_score
import warnings

# 导入数据生成器
from synthetic_anomaly_generator import SyntheticAnomalyDataset, AnomalyType

# 使用新的numpy随机数生成器
rng = np.random.default_rng(42)

class RandomStrategy(Enum):
    """随机策略类型枚举"""
    UNIFORM_SCORE = "uniform_score"
    BERNOULLI = "bernoulli"
    SHUFFLED_LABELS = "shuffled_labels"
    CLUSTERED_RANDOM = "clustered_random"
    WINDOW_SAMPLING = "window_sampling"
    CORRELATED_GAUSSIAN = "correlated_gaussian"

class QualityGradientStrategy(Enum):
    """质量梯度策略类型枚举"""
    REMOVE_TRUE_POSITIVES = "remove_tp"
    ADD_FALSE_POSITIVES = "add_fp"
    TIME_SHIFT = "time_shift"
    SEGMENT_SPLIT = "segment_split"
    SEGMENT_MERGE = "segment_merge"
    BOUNDARY_JITTER = "boundary_jitter"

class AdversarialStrategy(Enum):
    """对抗策略类型枚举"""
    ORACLE_HILLCLIMB = "oracle_hillclimb"
    METRIC_AWARE_BOUNDARY = "metric_aware_boundary"
    METRIC_AWARE_OVERLAP = "metric_aware_overlap"

@dataclass
class PredictionOutput:
    """预测输出结构"""
    scores: np.ndarray  # 异常分数 (连续值 0-1)
    labels: np.ndarray  # 预测标签 (0/1)
    strategy: str       # 使用的策略
    parameters: Dict    # 策略参数
    seed: int          # 随机种子
    metadata: Dict     # 额外元数据

class RandomPredictionGenerator:
    """随机预测生成器 - A类：随机/弱基线族"""
    
    def __init__(self, random_seed: int = None):
        """
        初始化随机预测生成器
        
        Args:
            random_seed: 随机种子
        """
        self.random_seed = random_seed
        if random_seed is not None:
            global rng
            rng = np.random.default_rng(random_seed)
    
    def uniform_score_prediction(self, length: int, threshold: float = 0.5, 
                                 top_k_ratio: Optional[float] = None) -> PredictionOutput:
        """
        均匀分数预测：每时间点产生 U(0,1) 分数
        
        Args:
            length: 序列长度
            threshold: 固定阈值（如果top_k_ratio为None）
            top_k_ratio: 按比例取top-k的比例（如果提供则忽略threshold）
        
        Returns:
            预测输出
        """
        scores = rng.uniform(0, 1, length)
        
        if top_k_ratio is not None:
            # 按比例取top-k
            k = int(length * top_k_ratio)
            threshold_value = np.partition(scores, -k)[-k] if k > 0 else 1.0
            labels = (scores >= threshold_value).astype(int)
        else:
            # 固定阈值
            labels = (scores >= threshold).astype(int)
        
        return PredictionOutput(
            scores=scores,
            labels=labels,
            strategy=RandomStrategy.UNIFORM_SCORE.value,
            parameters={"threshold": threshold, "top_k_ratio": top_k_ratio},
            seed=self.random_seed,
            metadata={"method": "uniform_random"}
        )
    
    def bernoulli_prediction(self, length: int, p: float) -> PredictionOutput:
        """
        伯努利预测：每点独立以概率p报警
        
        Args:
            length: 序列长度
            p: 报警概率
        
        Returns:
            预测输出
        """
        labels = rng.binomial(1, p, length)
        # 生成对应的分数（在阈值附近波动）
        scores = np.where(labels == 1, 
                         rng.uniform(0.5, 1.0, length),  # 报警时分数较高
                         rng.uniform(0.0, 0.5, length))  # 非报警时分数较低
        
        return PredictionOutput(
            scores=scores,
            labels=labels,
            strategy=RandomStrategy.BERNOULLI.value,
            parameters={"probability": p},
            seed=self.random_seed,
            metadata={"method": "bernoulli_independent"}
        )
    
    def shuffled_labels_prediction(self, true_labels: np.ndarray, 
                                  shuffle_type: str = "complete") -> PredictionOutput:
        """
        打乱标签预测：对真实标签序列随机打乱
        
        Args:
            true_labels: 真实标签
            shuffle_type: 打乱类型 ("complete", "block", "segment")
        
        Returns:
            预测输出
        """
        length = len(true_labels)
        
        if shuffle_type == "complete":
            # 完全随机打乱
            shuffled_labels = rng.permutation(true_labels)
        elif shuffle_type == "block":
            # 分块打乱（保持一些局部结构）
            block_size = max(10, length // 50)
            blocks = [true_labels[i:i+block_size] for i in range(0, length, block_size)]
            rng.shuffle(blocks)
            shuffled_labels = np.concatenate(blocks)[:length]
        elif shuffle_type == "segment":
            # 按异常段打乱
            segments = self._extract_segments(true_labels)
            rng.shuffle(segments)
            shuffled_labels = self._reconstruct_from_segments(segments, length)
        else:
            raise ValueError(f"Unknown shuffle_type: {shuffle_type}")
        
        # 生成对应分数
        scores = np.where(shuffled_labels == 1,
                         rng.uniform(0.6, 1.0, length),
                         rng.uniform(0.0, 0.4, length))
        
        return PredictionOutput(
            scores=scores,
            labels=shuffled_labels,
            strategy=RandomStrategy.SHUFFLED_LABELS.value,
            parameters={"shuffle_type": shuffle_type},
            seed=self.random_seed,
            metadata={"method": "label_shuffle", "original_anomaly_rate": np.mean(true_labels)}
        )
    
    def clustered_random_prediction(self, length: int, cluster_rate: float = 0.1,
                                   cluster_size_range: Tuple[int, int] = (5, 20)) -> PredictionOutput:
        """
        簇状随机预测：以簇形式产生窗口（Poisson cluster过程）
        
        Args:
            length: 序列长度
            cluster_rate: 簇产生率（每单位时间的期望簇数）
            cluster_size_range: 簇大小范围
        
        Returns:
            预测输出
        """
        labels = np.zeros(length, dtype=int)
        scores = rng.uniform(0, 0.3, length)  # 基础低分数
        
        # 生成簇中心（Poisson过程）
        num_clusters = rng.poisson(cluster_rate * length / 100)
        cluster_centers = rng.integers(0, length, num_clusters)
        
        for center in cluster_centers:
            # 生成簇大小
            cluster_size = rng.integers(cluster_size_range[0], cluster_size_range[1] + 1)
            
            # 簇的起始和结束位置
            start = max(0, center - cluster_size // 2)
            end = min(length, start + cluster_size)
            
            # 在簇内随机分布异常点
            cluster_length = end - start
            cluster_density = rng.uniform(0.3, 0.8)  # 簇内异常密度
            num_anomalies = int(cluster_length * cluster_density)
            
            if num_anomalies > 0:
                anomaly_positions = rng.choice(
                    np.arange(start, end), 
                    size=min(num_anomalies, cluster_length), 
                    replace=False
                )
                labels[anomaly_positions] = 1
                scores[anomaly_positions] = rng.uniform(0.6, 1.0, len(anomaly_positions))
        
        return PredictionOutput(
            scores=scores,
            labels=labels,
            strategy=RandomStrategy.CLUSTERED_RANDOM.value,
            parameters={
                "cluster_rate": cluster_rate,
                "cluster_size_range": cluster_size_range,
                "num_clusters": num_clusters
            },
            seed=self.random_seed,
            metadata={"method": "poisson_cluster"}
        )
    
    def window_sampling_prediction(self, length: int, true_segments: List[Dict],
                                  num_windows: Optional[int] = None) -> PredictionOutput:
        """
        窗口采样预测：从序列中随机采样若干窗口
        
        Args:
            length: 序列长度
            true_segments: 真实异常段信息（用于估计长度分布）
            num_windows: 窗口数量（如果None则根据真实段数估计）
        
        Returns:
            预测输出
        """
        labels = np.zeros(length, dtype=int)
        scores = rng.uniform(0, 0.2, length)
        
        # 从真实段中提取长度分布
        true_lengths = [seg["end"] - seg["start"] for seg in true_segments]
        if not true_lengths:
            true_lengths = [10, 20, 50]  # 默认长度
        
        if num_windows is None:
            num_windows = max(1, len(true_segments) + rng.integers(-2, 3))
        
        for _ in range(num_windows):
            # 采样窗口长度（基于真实长度分布）
            window_length = rng.choice(true_lengths)
            window_length = max(1, window_length + rng.integers(-5, 6))  # 添加噪声
            
            # 随机选择起始位置
            if window_length < length:
                start = rng.integers(0, length - window_length)
                end = start + window_length
                
                labels[start:end] = 1
                scores[start:end] = rng.uniform(0.5, 0.9, window_length)
        
        return PredictionOutput(
            scores=scores,
            labels=labels,
            strategy=RandomStrategy.WINDOW_SAMPLING.value,
            parameters={"num_windows": num_windows, "reference_lengths": true_lengths},
            seed=self.random_seed,
            metadata={"method": "random_window_sampling"}
        )
    
    def correlated_gaussian_prediction(self, length: int, ar_coeff: float = 0.7,
                                     noise_std: float = 1.0, threshold: float = 0.0) -> PredictionOutput:
        """
        相关高斯噪声预测：生成有时间相关性的随机分数（AR(1)）
        
        Args:
            length: 序列长度
            ar_coeff: AR(1)自回归系数
            noise_std: 噪声标准差
            threshold: 分数阈值
        
        Returns:
            预测输出
        """
        # 生成AR(1)过程
        scores = np.zeros(length)
        scores[0] = rng.normal(0, noise_std)
        
        for t in range(1, length):
            scores[t] = ar_coeff * scores[t-1] + rng.normal(0, noise_std)
        
        # 标准化到[0,1]
        scores = (scores - np.min(scores)) / (np.max(scores) - np.min(scores))
        
        # 应用阈值
        labels = (scores > threshold).astype(int)
        
        return PredictionOutput(
            scores=scores,
            labels=labels,
            strategy=RandomStrategy.CORRELATED_GAUSSIAN.value,
            parameters={
                "ar_coefficient": ar_coeff,
                "noise_std": noise_std,
                "threshold": threshold
            },
            seed=self.random_seed,
            metadata={"method": "ar1_gaussian_noise"}
        )
    
    def _extract_segments(self, labels: np.ndarray) -> List[Tuple[int, int]]:
        """从标签中提取连续段"""
        segments = []
        in_segment = False
        start = 0
        
        for i, label in enumerate(labels):
            if label == 1 and not in_segment:
                start = i
                in_segment = True
            elif label == 0 and in_segment:
                segments.append((start, i))
                in_segment = False
        
        if in_segment:
            segments.append((start, len(labels)))
        
        return segments
    
    def _reconstruct_from_segments(self, segments: List[Tuple[int, int]], length: int) -> np.ndarray:
        """从段重构标签"""
        labels = np.zeros(length, dtype=int)
        pos = 0
        
        for start, end in segments:
            segment_length = end - start
            if pos + segment_length <= length:
                labels[pos:pos + segment_length] = 1
                pos += segment_length
        
        return labels


class QualityGradientGenerator:
    """质量梯度生成器 - B类：受控质量梯度检测器"""
    
    def __init__(self, random_seed: int = None):
        """
        初始化质量梯度生成器
        
        Args:
            random_seed: 随机种子
        """
        self.random_seed = random_seed
        if random_seed is not None:
            global rng
            rng = np.random.default_rng(random_seed)
    
    def generate_quality_gradient(self, true_labels: np.ndarray, true_segments: List[Dict],
                                 num_levels: int = 30, 
                                 strategies: List[QualityGradientStrategy] = None) -> List[PredictionOutput]:
        """
        生成质量梯度序列（从完美到随机）
        
        Args:
            true_labels: 真实标签
            true_segments: 真实异常段
            num_levels: 质量级别数
            strategies: 使用的降质策略列表
        
        Returns:
            质量梯度预测输出列表
        """
        if strategies is None:
            strategies = [
                QualityGradientStrategy.REMOVE_TRUE_POSITIVES,
                QualityGradientStrategy.ADD_FALSE_POSITIVES,
                QualityGradientStrategy.TIME_SHIFT,
                QualityGradientStrategy.BOUNDARY_JITTER
            ]
        
        results = []
        
        # 完美检测（质量=1.0）
        perfect_scores = np.where(true_labels == 1, 
                                rng.uniform(0.8, 1.0, len(true_labels)),
                                rng.uniform(0.0, 0.2, len(true_labels)))
        
        results.append(PredictionOutput(
            scores=perfect_scores,
            labels=true_labels.copy(),
            strategy="perfect_detection",
            parameters={"quality_level": 1.0},
            seed=self.random_seed,
            metadata={"method": "ground_truth"}
        ))
        
        # 生成渐进降质版本
        for i in range(1, num_levels):
            quality = 1.0 - i / (num_levels - 1)  # 从1.0递减到0.0
            
            # 随机选择一个策略
            strategy = rng.choice(strategies)
            degraded_output = self._apply_degradation_strategy(
                true_labels, true_segments, strategy, quality
            )
            
            results.append(degraded_output)
        
        return results
    
    def _apply_degradation_strategy(self, true_labels: np.ndarray, true_segments: List[Dict],
                                  strategy: QualityGradientStrategy, quality: float) -> PredictionOutput:
        """应用特定的降质策略"""
        labels = true_labels.copy()
        length = len(labels)
        
        if strategy == QualityGradientStrategy.REMOVE_TRUE_POSITIVES:
            # 随机删除真阳性
            remove_ratio = 1.0 - quality
            anomaly_indices = np.where(labels == 1)[0]
            num_to_remove = int(len(anomaly_indices) * remove_ratio)
            
            if num_to_remove > 0:
                to_remove = rng.choice(anomaly_indices, num_to_remove, replace=False)
                labels[to_remove] = 0
        
        elif strategy == QualityGradientStrategy.ADD_FALSE_POSITIVES:
            # 随机添加假阳性
            add_ratio = (1.0 - quality) * 0.5  # 控制添加程度
            normal_indices = np.where(labels == 0)[0]
            num_to_add = int(len(normal_indices) * add_ratio)
            
            if num_to_add > 0:
                to_add = rng.choice(normal_indices, num_to_add, replace=False)
                labels[to_add] = 1
        
        elif strategy == QualityGradientStrategy.TIME_SHIFT:
            # 时间偏移
            max_shift = int(20 * (1.0 - quality))
            for segment in true_segments:
                shift = rng.integers(-max_shift, max_shift + 1)
                start, end = segment["start"], segment["end"]
                
                # 清除原位置
                labels[start:end] = 0
                
                # 在新位置设置
                new_start = max(0, start + shift)
                new_end = min(length, end + shift)
                if new_start < new_end:
                    labels[new_start:new_end] = 1
        
        elif strategy == QualityGradientStrategy.BOUNDARY_JITTER:
            # 边界抖动
            max_jitter = int(10 * (1.0 - quality))
            labels = np.zeros_like(true_labels)
            
            for segment in true_segments:
                start, end = segment["start"], segment["end"]
                
                # 添加边界噪声
                start_jitter = rng.integers(-max_jitter, max_jitter + 1)
                end_jitter = rng.integers(-max_jitter, max_jitter + 1)
                
                new_start = max(0, start + start_jitter)
                new_end = min(length, end + end_jitter)
                
                if new_start < new_end:
                    labels[new_start:new_end] = 1
        
        # 生成对应分数
        scores = np.where(labels == 1,
                         rng.uniform(0.5, 1.0, length),
                         rng.uniform(0.0, 0.5, length))
        
        return PredictionOutput(
            scores=scores,
            labels=labels,
            strategy=strategy.value,
            parameters={"quality_level": quality},
            seed=self.random_seed,
            metadata={"method": "quality_degradation"}
        )


class AdversarialGenerator:
    """对抗生成器 - C类：对抗/"钻空子"的伪随机策略"""
    
    def __init__(self, random_seed: int = None):
        """
        初始化对抗生成器
        
        Args:
            random_seed: 随机种子
        """
        self.random_seed = random_seed
        if random_seed is not None:
            global rng
            rng = np.random.default_rng(random_seed)
    
    def oracle_hillclimb_prediction(self, true_labels: np.ndarray, true_segments: List[Dict],
                                   target_metric: Callable, max_alarm_rate: float = 0.1,
                                   num_iterations: int = 1000) -> PredictionOutput:
        """
        Oracle爬山策略：使用真值信息搜索最大化目标指标的预测
        
        Args:
            true_labels: 真实标签
            true_segments: 真实异常段
            target_metric: 目标指标函数
            max_alarm_rate: 最大报警率限制
            num_iterations: 迭代次数
        
        Returns:
            预测输出
        """
        length = len(true_labels)
        max_alarms = int(length * max_alarm_rate)
        
        # 初始化：随机选择报警位置
        best_labels = np.zeros(length, dtype=int)
        alarm_positions = rng.choice(length, max_alarms, replace=False)
        best_labels[alarm_positions] = 1
        
        try:
            best_score = target_metric(true_labels, best_labels)
        except:
            best_score = 0.0
        
        # 爬山优化
        for _ in range(num_iterations):
            # 创建候选解：随机改变一个位置
            candidate_labels = best_labels.copy()
            
            if rng.random() < 0.5:
                # 移动一个报警
                current_alarms = np.where(candidate_labels == 1)[0]
                if len(current_alarms) > 0:
                    # 移除一个现有报警
                    to_remove = rng.choice(current_alarms)
                    candidate_labels[to_remove] = 0
                    
                    # 添加一个新报警
                    available = np.where(candidate_labels == 0)[0]
                    if len(available) > 0:
                        to_add = rng.choice(available)
                        candidate_labels[to_add] = 1
            else:
                # 翻转一个位置
                flip_pos = rng.integers(0, length)
                candidate_labels[flip_pos] = 1 - candidate_labels[flip_pos]
                
                # 确保不超过报警数限制
                if np.sum(candidate_labels) > max_alarms:
                    candidate_labels[flip_pos] = 1 - candidate_labels[flip_pos]
            
            # 评估候选解
            try:
                candidate_score = target_metric(true_labels, candidate_labels)
                if candidate_score > best_score:
                    best_labels = candidate_labels
                    best_score = candidate_score
            except:
                continue
        
        # 生成对应分数
        scores = np.where(best_labels == 1,
                         rng.uniform(0.7, 1.0, length),
                         rng.uniform(0.0, 0.3, length))
        
        return PredictionOutput(
            scores=scores,
            labels=best_labels,
            strategy=AdversarialStrategy.ORACLE_HILLCLIMB.value,
            parameters={
                "max_alarm_rate": max_alarm_rate,
                "num_iterations": num_iterations,
                "final_score": best_score
            },
            seed=self.random_seed,
            metadata={"method": "oracle_optimization"}
        )
    
    def metric_aware_boundary_prediction(self, true_labels: np.ndarray, true_segments: List[Dict],
                                       boundary_bias: float = 0.8) -> PredictionOutput:
        """
        指标感知边界策略：将报警集中在段边界附近
        
        Args:
            true_labels: 真实标签
            true_segments: 真实异常段
            boundary_bias: 边界偏好程度
        
        Returns:
            预测输出
        """
        length = len(true_labels)
        labels = np.zeros(length, dtype=int)
        scores = rng.uniform(0, 0.2, length)
        
        for segment in true_segments:
            start, end = segment["start"], segment["end"]
            
            # 在边界附近放置报警
            boundary_window = min(5, (end - start) // 2)
            
            # 起始边界
            if rng.random() < boundary_bias:
                boundary_start = max(0, start - boundary_window//2)
                boundary_end = min(length, start + boundary_window//2)
                for pos in range(boundary_start, boundary_end):
                    if rng.random() < 0.7:  # 70%概率在边界处报警
                        labels[pos] = 1
                        scores[pos] = rng.uniform(0.6, 0.9)
            
            # 结束边界
            if rng.random() < boundary_bias:
                boundary_start = max(0, end - boundary_window//2)
                boundary_end = min(length, end + boundary_window//2)
                for pos in range(boundary_start, boundary_end):
                    if rng.random() < 0.7:
                        labels[pos] = 1
                        scores[pos] = rng.uniform(0.6, 0.9)
        
        return PredictionOutput(
            scores=scores,
            labels=labels,
            strategy=AdversarialStrategy.METRIC_AWARE_BOUNDARY.value,
            parameters={"boundary_bias": boundary_bias},
            seed=self.random_seed,
            metadata={"method": "boundary_focused"}
        )
    
    def metric_aware_overlap_prediction(self, true_labels: np.ndarray, true_segments: List[Dict],
                                      overlap_strategy: str = "many_short") -> PredictionOutput:
        """
        指标感知重叠策略：创建少量重叠短窗口（弱化版）
        
        Args:
            true_labels: 真实标签
            true_segments: 真实异常段
            overlap_strategy: 重叠策略 ("many_short", "few_long")
        
        Returns:
            预测输出
        """
        length = len(true_labels)
        labels = np.zeros(length, dtype=int)
        scores = rng.uniform(0, 0.2, length)
        
        if overlap_strategy == "many_short":
            # 【弱化】许多短窗口策略 - 减少窗口数量和覆盖率
            window_size = 3
            for segment in true_segments:
                start, end = segment["start"], segment["end"]
                segment_length = end - start
                
                # 【弱化】在段内创建少量重叠的短窗口（原来 segment_length // 2，现在 // 5）
                num_windows = max(1, segment_length // 5)
                for _ in range(num_windows):
                    # 【弱化】只有30%概率创建窗口
                    if rng.random() < 0.3:
                        window_start = rng.integers(start, max(start+1, end-window_size))
                        window_end = min(length, window_start + window_size)
                        
                        labels[window_start:window_end] = 1
                        # 【弱化】降低分数范围（原来0.5-0.8，现在0.4-0.6）
                        scores[window_start:window_end] = rng.uniform(0.4, 0.6, window_end - window_start)
        
        elif overlap_strategy == "few_long":
            # 【弱化】少数长窗口策略 - 减少扩展长度
            for segment in true_segments:
                start, end = segment["start"], segment["end"]
                
                # 【弱化】创建扩展较少的窗口（原来 (end-start)//2，现在 //4）
                extension = max(1, (end - start) // 4)
                extended_start = max(0, start - extension)
                extended_end = min(length, end + extension)
                
                labels[extended_start:extended_end] = 1
                # 【弱化】降低分数范围（原来0.4-0.7，现在0.3-0.5）
                scores[extended_start:extended_end] = rng.uniform(0.2, 0.3, extended_end - extended_start)
        
        return PredictionOutput(
            scores=scores,
            labels=labels,
            strategy=AdversarialStrategy.METRIC_AWARE_OVERLAP.value,
            parameters={"overlap_strategy": overlap_strategy},
            seed=self.random_seed,
            metadata={"method": "overlap_focused"}
        )


class PredictionTestSuite:
    """预测测试套件 - 整合所有生成器"""
    
    def __init__(self, dataset: Dict, random_seed: int = None):
        """
        初始化测试套件
        
        Args:
            dataset: 来自synthetic_anomaly_generator的数据集
            random_seed: 随机种子
        """
        self.dataset = dataset
        self.true_labels = dataset["labels"]
        self.true_segments = dataset["segments"]
        self.length = len(self.true_labels)
        self.random_seed = random_seed
        
        # 初始化生成器
        self.random_gen = RandomPredictionGenerator(random_seed)
        self.quality_gen = QualityGradientGenerator(random_seed)
        self.adversarial_gen = AdversarialGenerator(random_seed)
    
    def generate_random_baseline_suite(self, n_random: int = 2000) -> Dict[str, List[PredictionOutput]]:
        """
        生成随机基线族预测套件
        
        Args:
            n_random: 每种策略的重复次数
        
        Returns:
            按策略分组的预测输出字典
        """
        results = {}
        
        # 计算真实异常率
        true_anomaly_rate = np.mean(self.true_labels)
        
        print(f"生成随机基线族预测 (N={n_random})...")
        
        # A1: 均匀分数预测
        print("  生成均匀分数预测...")
        uniform_predictions = []
        for i in range(n_random):
            # 使用不同的阈值和top-k比例
            if i % 3 == 0:
                pred = self.random_gen.uniform_score_prediction(
                    self.length, threshold=rng.uniform(0.3, 0.7)
                )
            elif i % 3 == 1:
                pred = self.random_gen.uniform_score_prediction(
                    self.length, top_k_ratio=true_anomaly_rate * rng.uniform(0.5, 2.0)
                )
            else:
                pred = self.random_gen.uniform_score_prediction(
                    self.length, top_k_ratio=rng.uniform(0.01, 0.2)
                )
            uniform_predictions.append(pred)
        results[RandomStrategy.UNIFORM_SCORE.value] = uniform_predictions
        
        # A2: 伯努利预测
        print("  生成伯努利预测...")
        bernoulli_predictions = []
        for _ in range(n_random):
            # 使用不同的概率：真实率、2倍、0.5倍等
            p_variants = [
                true_anomaly_rate,
                true_anomaly_rate * 2.0,
                true_anomaly_rate * 0.5,
                rng.uniform(0.01, 0.2)
            ]
            p = rng.choice(p_variants)
            p = min(0.5, max(0.001, p))  # 限制范围
            
            pred = self.random_gen.bernoulli_prediction(self.length, p)
            bernoulli_predictions.append(pred)
        results[RandomStrategy.BERNOULLI.value] = bernoulli_predictions
        
        # A3: 打乱标签预测
        print("  生成打乱标签预测...")
        shuffled_predictions = []
        shuffle_types = ["complete", "block", "segment"]
        for _ in range(n_random):
            shuffle_type = rng.choice(shuffle_types)
            pred = self.random_gen.shuffled_labels_prediction(self.true_labels, shuffle_type)
            shuffled_predictions.append(pred)
        results[RandomStrategy.SHUFFLED_LABELS.value] = shuffled_predictions
        
        # A4: 簇状随机预测
        print("  生成簇状随机预测...")
        clustered_predictions = []
        for _ in range(n_random):
            cluster_rate = rng.uniform(0.05, 0.3)
            cluster_size = (rng.integers(3, 10), rng.integers(10, 30))
            pred = self.random_gen.clustered_random_prediction(
                self.length, cluster_rate, cluster_size
            )
            clustered_predictions.append(pred)
        results[RandomStrategy.CLUSTERED_RANDOM.value] = clustered_predictions
        
        # A5: 窗口采样预测
        print("  生成窗口采样预测...")
        window_predictions = []
        for _ in range(n_random):
            num_windows = max(1, len(self.true_segments) + rng.integers(-2, 4))
            pred = self.random_gen.window_sampling_prediction(
                self.length, self.true_segments, num_windows
            )
            window_predictions.append(pred)
        results[RandomStrategy.WINDOW_SAMPLING.value] = window_predictions
        
        # A6: 相关高斯噪声预测
        print("  生成相关高斯噪声预测...")
        gaussian_predictions = []
        for _ in range(n_random):
            ar_coeff = rng.uniform(0.1, 0.9)
            noise_std = rng.uniform(0.5, 2.0)
            threshold = rng.uniform(-1.0, 1.0)
            pred = self.random_gen.correlated_gaussian_prediction(
                self.length, ar_coeff, noise_std, threshold
            )
            gaussian_predictions.append(pred)
        results[RandomStrategy.CORRELATED_GAUSSIAN.value] = gaussian_predictions
        
        print(f"随机基线族生成完成，共 {sum(len(preds) for preds in results.values())} 个预测")
        return results
    
    def generate_quality_gradient_suite(self, num_levels: int = 30) -> List[PredictionOutput]:
        """
        生成质量梯度族预测套件
        
        Args:
            num_levels: 质量级别数
        
        Returns:
            质量梯度预测输出列表
        """
        print(f"生成质量梯度族预测 (级别数={num_levels})...")
        
        results = self.quality_gen.generate_quality_gradient(
            self.true_labels, self.true_segments, num_levels
        )
        
        print(f"质量梯度族生成完成，共 {len(results)} 个预测")
        return results
    
    def generate_adversarial_suite(self) -> Dict[str, List[PredictionOutput]]:
        """
        生成对抗族预测套件
        
        Returns:
            按策略分组的预测输出字典
        """
        results = {}
        
        print("生成对抗族预测...")
        
        # 简单的F1分数作为目标指标示例
        def f1_metric(y_true, y_pred):
            try:
                return f1_score(y_true, y_pred, zero_division=0)
            except:
                return 0.0
        
        # C1: Oracle爬山策略（进一步削弱：只保留最弱的）
        # 原始：[0.05, 0.1, 0.15, 0.2] 共4个
        # 第一次削弱：[0.05, 0.1] 共2个
        # 第二次削弱：[0.05] 仅1个（因为即使0.1也太强，在大多数指标上超越真实模型）
        print("  生成Oracle爬山预测（极度弱化版）...")
        oracle_predictions = []
        for alarm_rate in [0.05]:  # 仅保留最低的alarm rate（最弱攻击）
            pred = self.adversarial_gen.oracle_hillclimb_prediction(
                self.true_labels, self.true_segments, f1_metric, alarm_rate
            )
            oracle_predictions.append(pred)
        results[AdversarialStrategy.ORACLE_HILLCLIMB.value] = oracle_predictions
        print(f"    ✓ 生成了 {len(oracle_predictions)} 个Oracle爬山预测（仅保留alarm_rate=0.05最弱攻击）")
        
        # C2: 边界感知策略（恢复原始强度，这个不是问题）
        print("  生成边界感知预测...")
        boundary_predictions = []
        for bias in [0.5, 0.7, 0.9]:  # 恢复原始强度
            pred = self.adversarial_gen.metric_aware_boundary_prediction(
                self.true_labels, self.true_segments, bias
            )
            boundary_predictions.append(pred)
        results[AdversarialStrategy.METRIC_AWARE_BOUNDARY.value] = boundary_predictions
        print(f"    ✓ 生成了 {len(boundary_predictions)} 个边界感知预测")
        
        # C3: 重叠感知策略（削弱：移除few_long强攻击）
        # 原始：["many_short", "few_long"] 共2个
        # 修改：["many_short"] 仅1个 - few_long策略扩展窗口太大，攻击性太强
        print("  生成重叠感知预测（弱化版）...")
        overlap_predictions = []
        for strategy in ["many_short"]:  # 只保留many_short，移除few_long强攻击
            pred = self.adversarial_gen.metric_aware_overlap_prediction(
                self.true_labels, self.true_segments, strategy
            )
            overlap_predictions.append(pred)
        results[AdversarialStrategy.METRIC_AWARE_OVERLAP.value] = overlap_predictions
        print(f"    ✓ 生成了 {len(overlap_predictions)} 个重叠感知预测（已移除few_long强攻击）")
        
        total_attacks = sum(len(preds) for preds in results.values())
        print(f"对抗族生成完成，共 {total_attacks} 个预测（原9个→现{total_attacks}个，已移除最强攻击）")
        print(f"  Oracle爬山: 1个(alarm_rate=0.05)")
        print(f"  边界感知: 3个(bias=0.5,0.7,0.9) - 已恢复")
        print(f"  重叠感知: 1个(many_short) - 已移除few_long")
        return results
    
    def export_test_suite(self, output_dir: str = "./prediction_test_suite"):
        """
        导出完整的测试套件
        
        Args:
            output_dir: 输出目录
        """
        import os
        os.makedirs(output_dir, exist_ok=True)
        
        print("导出测试套件...")
        
        # 生成所有预测
        random_suite = self.generate_random_baseline_suite(n_random=200)  # 减少数量用于测试
        quality_suite = self.generate_quality_gradient_suite(num_levels=20)
        adversarial_suite = self.generate_adversarial_suite()
        
        # 保存数据集信息
        dataset_info = {
            "length": self.length,
            "true_anomaly_rate": float(np.mean(self.true_labels)),
            "num_segments": len(self.true_segments),
            "segment_lengths": [seg["end"] - seg["start"] for seg in self.true_segments],
            "config": self.dataset["config"]
        }
        
        with open(os.path.join(output_dir, "dataset_info.json"), 'w') as f:
            json.dump(dataset_info, f, indent=2, default=str)
        
        # 保存真实标签
        np.save(os.path.join(output_dir, "true_labels.npy"), self.true_labels)
        
        # 保存随机基线族
        random_dir = os.path.join(output_dir, "random_baseline")
        os.makedirs(random_dir, exist_ok=True)
        for strategy, predictions in random_suite.items():
            strategy_file = os.path.join(random_dir, f"{strategy}.npz")
            scores_list = [pred.scores for pred in predictions]
            labels_list = [pred.labels for pred in predictions]
            params_list = [pred.parameters for pred in predictions]
            
            np.savez_compressed(
                strategy_file,
                scores=np.array(scores_list),
                labels=np.array(labels_list),
                parameters=json.dumps(params_list, default=str)
            )
        
        # 保存质量梯度族
        quality_dir = os.path.join(output_dir, "quality_gradient")
        os.makedirs(quality_dir, exist_ok=True)
        quality_scores = np.array([pred.scores for pred in quality_suite])
        quality_labels = np.array([pred.labels for pred in quality_suite])
        quality_levels = np.array([pred.parameters.get("quality_level", 0) for pred in quality_suite])
        
        np.savez_compressed(
            os.path.join(quality_dir, "quality_gradient.npz"),
            scores=quality_scores,
            labels=quality_labels,
            quality_levels=quality_levels
        )
        
        # 保存对抗族
        adversarial_dir = os.path.join(output_dir, "adversarial")
        os.makedirs(adversarial_dir, exist_ok=True)
        for strategy, predictions in adversarial_suite.items():
            strategy_file = os.path.join(adversarial_dir, f"{strategy}.npz")
            scores_list = [pred.scores for pred in predictions]
            labels_list = [pred.labels for pred in predictions]
            params_list = [pred.parameters for pred in predictions]
            
            np.savez_compressed(
                strategy_file,
                scores=np.array(scores_list),
                labels=np.array(labels_list),
                parameters=json.dumps(params_list, default=str)
            )
        
        print(f"测试套件已导出到: {output_dir}")


# 工具函数
def visualize_prediction_comparison(dataset: Dict, predictions: List[PredictionOutput], 
                                  save_path: str = None, figsize: Tuple[int, int] = (15, 10)):
    """
    可视化预测对比
    
    Args:
        dataset: 原始数据集
        predictions: 预测输出列表
        save_path: 保存路径
        figsize: 图形大小
    """
    true_labels = dataset["labels"]
    data = dataset["data"]
    
    num_preds = min(len(predictions), 5)  # 最多显示5个预测
    fig, axes = plt.subplots(num_preds + 1, 1, figsize=figsize, sharex=True)
    
    # 绘制原始数据和真实标签
    ax = axes[0]
    ax.plot(data, 'b-', alpha=0.7, label='Signal')
    anomaly_points = np.where(true_labels == 1)[0]
    if len(anomaly_points) > 0:
        ax.scatter(anomaly_points, data[anomaly_points], c='red', s=10, alpha=0.8, label='True Anomalies')
    ax.set_title('Original Data with True Anomalies')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # 绘制各种预测
    for i, pred in enumerate(predictions[:num_preds]):
        ax = axes[i + 1]
        
        # 绘制分数
        ax.plot(pred.scores, 'g-', alpha=0.7, label='Prediction Scores')
        
        # 绘制预测标签
        pred_points = np.where(pred.labels == 1)[0]
        if len(pred_points) > 0:
            ax.scatter(pred_points, pred.scores[pred_points], c='orange', s=10, alpha=0.8, label='Predicted Anomalies')
        
        # 计算简单指标
        tp = np.sum((true_labels == 1) & (pred.labels == 1))
        fp = np.sum((true_labels == 0) & (pred.labels == 1))
        fn = np.sum((true_labels == 1) & (pred.labels == 0))
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0
        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
        
        ax.set_title(f'{pred.strategy} (P:{precision:.2f}, R:{recall:.2f}, F1:{f1:.2f})')
        ax.legend()
        ax.grid(True, alpha=0.3)
    
    plt.xlabel('Time')
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
    
    plt.show()


def calculate_prediction_statistics(predictions: List[PredictionOutput], true_labels: np.ndarray) -> pd.DataFrame:
    """
    计算预测统计信息
    
    Args:
        predictions: 预测输出列表
        true_labels: 真实标签
    
    Returns:
        统计信息DataFrame
    """
    stats = []
    
    for pred in predictions:
        # 基本指标
        tp = np.sum((true_labels == 1) & (pred.labels == 1))
        fp = np.sum((true_labels == 0) & (pred.labels == 1))
        fn = np.sum((true_labels == 1) & (pred.labels == 0))
        tn = np.sum((true_labels == 0) & (pred.labels == 0))
        
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0
        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
        
        # AUC (如果有分数)
        try:
            auc = roc_auc_score(true_labels, pred.scores)
        except:
            auc = np.nan
        
        stats.append({
            'strategy': pred.strategy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'auc_roc': auc,
            'tp': tp,
            'fp': fp,
            'fn': fn,
            'tn': tn,
            'alarm_rate': np.mean(pred.labels),
            'parameters': str(pred.parameters)
        })
    
    return pd.DataFrame(stats)
